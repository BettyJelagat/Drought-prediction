{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8514525b-8897-4e47-8c86-18f9fa529f23",
   "metadata": {},
   "source": [
    "##Reading and visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bdd7ce-5f84-470f-98bb-d280613553a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m climatedata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1981-2024Daily summaries.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m],index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m#Make the year an index column\u001b[39;00m\n\u001b[0;32m      3\u001b[0m climatedata\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "climatedata = pd.read_csv(\"1981-2024Daily summaries.csv\", parse_dates=[\"DATE\"],index_col=\"DATE\") #Make the year an index column\n",
    "climatedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f228fcda-7bf4-4892-8057-d42cd6e7fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking information on the data\n",
    "print(climatedata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a199486-5f7d-4a01-affe-c64db54d4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a copy of the dataset to work with\n",
    "Core_weather = climatedata[[\"T2M_MAX\",\"T2M_MIN\",\"PRECTOTCORR\",\"QV2M\",\"WS2M\",\"GWETTOP\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13729317-53d3-4474-990f-53b19909154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns appropriately\n",
    "Core_weather.columns = [\"temp_max\",\"temp_min\",\"precip\",\"Humidity\",\"w_speed\",\"s_wetness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9553e-afd0-4510-a560-228fb82c2549",
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_weather"
   ]
  },
  {
   "cell_type": "raw",
   "id": "db85d2d6-b02b-457f-b2e3-d8f33816e3f2",
   "metadata": {},
   "source": [
    "## check for null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840bb0fa-66db-4289-b568-fa0834c0afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##According to the documentation, values with -999 are missing or were not recorded\n",
    "# to check percentage of null values per column\n",
    "Core_weather.apply(pd.isnull).sum()/Core_weather.shape[0]\n",
    "# As we can see below there are no null values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25cde27b-099e-4c02-9e96-07c7b661f932",
   "metadata": {},
   "source": [
    "#Veryfying that we have the correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8d409-5271-49f2-8690-3713da02077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datatypes\n",
    "Core_weather.dtypes\n",
    "\n",
    "#We find that all the data types are numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb00018-8d80-40aa-a1df-e787b70dfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the index to make sure its the right type\n",
    "Core_weather.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e5aa7-240b-402d-a1bd-5b0fd9499388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the index data -type is an object, it is treated as a string whereas it is a numerical data \n",
    "# Let's convert it to a pandas date time that makes manipulation of values and subsetting of values easier\n",
    "Core_weather.index = pd.to_datetime(Core_weather.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dedad9-3912-4e51-bd52-3dfed8df625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_weather.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a4838-9a8d-4b23-9458-77b96cb41727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting - Helps in avg monthly or yearly analysis\n",
    "#check index by year, month\n",
    "Core_weather.index.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd84f281-90d5-43fc-bb5c-f4a11a65c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_weather.index.month\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5598660-9f48-4f25-9f46-a89f782d68ce",
   "metadata": {},
   "source": [
    "##Analyzing the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8f032-d139-4751-baa8-73778d362508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the temp_max and temp_min\n",
    "Core_weather[[\"temp_max\",\"temp_min\"]].plot()\n",
    "\n",
    "#We find that there are outliers with temperature values -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894b586-6add-41f2-8e67-22ec6745a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Above you can notice that there were some tempretarures with values close to-999...this means that they were missing or were not recorded on that day\n",
    "#To fix that, lets find the sum of the cells with those values\n",
    "Core_weather.apply(lambda x: (x==-999).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fb2a1-82d1-4e59-93dd-b1d5e2a4799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# First replace the value-999 with NaN\n",
    "\n",
    "Core_weather.replace(-999, np.nan, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d5a90d-aa30-49fd-a7c9-638bfaef0ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then forward fill the NaN\n",
    "Core_weather.ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4307dc-e99a-4f39-92e8-fca43cd2e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To confirm if the -999 still exist, as we can see below it was replaced\n",
    "Core_weather.apply(lambda x: (x==-999).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac7b58-b06f-4c32-adc4-3ed6a3df8140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lets plot again to see the difference\n",
    "Core_weather[[\"temp_max\",\"temp_min\"]].plot()\n",
    "\n",
    "#The plots appear uniform without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9f8b6-a74c-4fa9-b2f9-4b4863b7564e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef845764-8d6c-4f37-98af-32743fc1b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the precipitation data\n",
    "Core_weather[[\"precip\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c22b48-f424-46c7-a426-8e4d27f665c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the humidity data\n",
    "Core_weather[[\"Humidity\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea70462-df9a-4167-ac82-5d19fddc1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the wind speed data\n",
    "Core_weather[[\"w_speed\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b8ad3-9c40-4d52-a5b4-5882d479cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the soil wetness data\n",
    "Core_weather[[\"s_wetness\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c613e-e0fa-48d2-8519-0a097cdb033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To perform seasonal or yearly analysis\n",
    "Core_weather.groupby(Core_weather.index.year).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3520c0-d84a-4a57-b1bd-15b88578997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To perform seasonal analysis by month\n",
    "Core_weather.groupby(Core_weather.index.month).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518f95b-90da-4862-9ebf-afd04509261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9bd41-3259-47a3-b0a5-bbe7cbb58167",
   "metadata": {},
   "outputs": [],
   "source": [
    "Core_weather.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25b59bad-5fa0-4fee-93d3-d3bf4b9c0da5",
   "metadata": {},
   "source": [
    "##To create a target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc253341-eb62-41c8-a1d8-85055d4b2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Core_weather.index = pd.to_datetime(Core_weather.index)\n",
    "\n",
    "# Compute the long-term average for each variable by day of the year\n",
    "Core_weather['day_of_year'] = Core_weather.index.dayofyear\n",
    "\n",
    "# Group by day of year to calculate long-term averages (e.g., average precipitation per day of year across all years)\n",
    "long_term_avg = Core_weather.groupby('day_of_year')[['s_wetness', 'w_speed', 'precip', 'Humidity', 'temp_max', 'temp_min']].mean()\n",
    "\n",
    "#Merge the long-term averages back to the original data\n",
    "Core_weather = pd.merge(Core_weather, long_term_avg, on='day_of_year', suffixes=('', '_long_term'))\n",
    "\n",
    "# Define thresholds for drought\n",
    "precipitation_threshold = 0.75  # 75% of the long-term average\n",
    "soil_moisture_threshold = 0.75  # 75% of the long-term average\n",
    "temp_max_threshold = 2  # 2°C above the long-term average\n",
    "def determine_drought(row):\n",
    "    # Check drought conditions element-wise\n",
    "    precip_drought = row['precip'] < (precipitation_threshold * row['precip_long_term'])\n",
    "    temp_max_drought = row['temp_max'] > (row['temp_max_long_term'] + temp_max_threshold)\n",
    "    soil_moisture_drought = row['s_wetness'] < (soil_moisture_threshold * row['s_wetness_long_term'])\n",
    "\n",
    "\n",
    "    # Use element-wise logical AND (&) and check if all conditions are True\n",
    "    if (precip_drought  &temp_max_drought & soil_moisture_drought).all():\n",
    "        return 1  # Drought occurred\n",
    "    else:\n",
    "        return 0  # No drought\n",
    "\n",
    "# Apply the function to each row\n",
    "Core_weather['drought_occurred'] = Core_weather.apply(determine_drought, axis=1)\n",
    "\n",
    "# Optional: Check the distribution of drought occurrences\n",
    "print(Core_weather['drought_occurred'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4d694-c266-4bf8-92eb-3f4b2b07bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can separate features (X) and target (y)\n",
    "X = Core_weather[[\"temp_max\",\"temp_min\",\"precip\",\"Humidity\",\"w_speed\",\"s_wetness\"]]  # Features\n",
    "y = Core_weather['drought_occurred']  # Target: 0 = No Drought, 1 = Drought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7274fa-606e-4c33-b1af-7b07f1fced67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the data (important for machine learning models)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_transformed = scaler.fit_transform(Core_weather[[\"temp_max\",\"temp_min\",\"precip\",\"Humidity\",\"w_speed\",\"s_wetness\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090d322-d8aa-42c1-b9c4-6fae6de9dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and test sets, use the scaled feature data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#To display the size of the training and testing sets\n",
    "print(f\"Training data size: {X_train.shape}\")\n",
    "print(f\"Test data size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85a796-777d-499d-bf56-f805f7de74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add standardized features back to the dataframe\n",
    "Standardised_data = pd.DataFrame(X_transformed, columns =X.columns)\n",
    "Standardised_data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b05b22a-391f-4375-976c-f7ec5072b39b",
   "metadata": {},
   "source": [
    "#Machine Learning Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0719918d-5e8a-4e60-ac16-81c903b95760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model - Training and Evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "## Initialize RandomForestClassifier with 100 estimators (trees)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix for Random Forest\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_predictions))\n",
    "\n",
    "# Classification Report for Random Forest\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c7457-b09b-4e9f-b67f-b6a0a9ada518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate the best model from grid search\n",
    "best_rf_predictions = best_rf_model.predict(X_test)\n",
    "best_rf_accuracy = accuracy_score(y_test, best_rf_predictions)\n",
    "print(f\"Optimized Random Forest Accuracy: {best_rf_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b522ea75-e950-4eab-87f6-fe5a8d90cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#. Support Vector Machine (SVM) - Training and Evaluation\n",
    "from sklearn.svm import SVC\n",
    "# Initialize the SVM model with a linear kernel\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix for SVM\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_predictions))\n",
    "\n",
    "# Classification Report for SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2061017-9e7f-4ac0-b895-6cfb61f7d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with GridSearchCV for SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV for SVM\n",
    "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=svm_param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_svm_model = grid_search_svm.best_estimator_\n",
    "\n",
    "# Evaluate the best model from grid search\n",
    "best_svm_predictions = best_svm_model.predict(X_test)\n",
    "best_svm_accuracy = accuracy_score(y_test, best_svm_predictions)\n",
    "print(f\"Optimized SVM Accuracy: {best_svm_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "260a8ced-f33b-4138-9d61-f09e01942f9e",
   "metadata": {},
   "source": [
    "#Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b457e9-0e82-416f-be74-20b182980b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Confusion Matrix Heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "rf_cm = confusion_matrix(y_test, rf_predictions)\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Drought', 'Drought'], yticklabels=['No Drought', 'Drought'])\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# SVM Confusion Matrix Heatmap\n",
    "svm_cm = confusion_matrix(y_test, svm_predictions)\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Drought', 'Drought'], yticklabels=['No Drought', 'Drought'])\n",
    "plt.title(\"SVM Confusion Matrix\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a7f6ce2-0205-472c-afeb-75ad303e19d4",
   "metadata": {},
   "source": [
    "##GIS Visualization for Early Warning Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45d922-40a3-497d-a109-03e2afdb0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load shapefile of Kenya \n",
    "kenya_shapefile = gpd.read_file('KEN_adm0.shp')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f67a1-11ce-404e-879c-6054ae7bfc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenya_shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46531e76-abfa-448f-a23d-22524ac4c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Eldama Ravine coordinates\n",
    "eldama_ravine_coords = [(35.7286 , 0.0483)]  # Longitude, Latitude\n",
    "predicted_drought = [rf_model.predict([[25, 10, 15,12,1.2,0.8]])[0]]  # Example input features for Eldama Ravine\n",
    "\n",
    "# Convert coordinates to GeoDataFrame\n",
    "geometry = [Point(xy) for xy in eldama_ravine_coords]\n",
    "geo_df = gpd.GeoDataFrame({'Latitude': [0.0483], 'Longitude': [35.7286], 'Predicted_Drought': predicted_drought}, geometry=geometry)\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "kenya_shapefile.plot(ax=ax, color='lightgray')  # Plot the Kenya boundary\n",
    "geo_df.plot(ax=ax, color=geo_df['Predicted_Drought'].map({1: 'red', 0: 'green'}), markersize=100)\n",
    "\n",
    "# Add label for Eldama Ravine\n",
    "for idx, row in geo_df.iterrows():\n",
    "    ax.text(row['Longitude'], row['Latitude'], 'Eldama Ravine', fontsize=12, ha='center', color='black')\n",
    "\n",
    "plt.title('Drought Prediction for Eldama Ravine')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084f770-d544-4bd5-8361-081fe9258f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation and Accuracy of the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58098eb1-87f3-4f39-9ce5-812c3b5fec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate the Random Forest model for Eldama Ravine\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Model Accuracy for Eldama Ravine: {rf_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the SVM model for Eldama Ravine\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f\"SVM Model Accuracy for Eldama Ravine: {svm_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac670937-314b-4bd9-91b1-4762f7e8b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We can see above that the random forest model is more accurate compared to the support vector Machine model(svm)\n",
    "##I therefor applied the random forest machine model in the Flask App."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
